{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tree import *\n",
    "from nv_tree_utilities import *\n",
    "import pandas as pd\n",
    "\n",
    "import mkl\n",
    "mkl.set_num_threads(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load yaz steak data\n",
    "data = pd.read_csv('yaz_steak.csv').values\n",
    "data = data[:,1:]\n",
    "\n",
    "X = data[:,0:24]\n",
    "Y = data[:,24] ## Demand for steak is found in column \"STEAK\"\n",
    "cu,co = 9,1\n",
    "X_train, X_test, Y_train, Y_test = X[range(0,600),:], X[range(600,760),:], Y[range(0,600)], Y[range(600,760)]\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0],X_train.shape[1])\n",
    "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1])\n",
    "Y_train = Y_train.reshape(-1,1)\n",
    "Y_test = Y_test.reshape(-1,1)\n",
    "\n",
    "\n",
    "X_list = [X_train]\n",
    "Y_list = [Y_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "p_list = [24]\n",
    "runs = 1 # 50\n",
    "n_jobs = 1 # 50\n",
    "n_trees = 100 # 500;\n",
    "N_list = [600]\n",
    "# Nx_test = 200\n",
    "# Ny_test = 2000\n",
    "# Ny_train = 1000\n",
    "\n",
    "\n",
    "b_list = np.array([9.])#, 1.]) ## backlog\n",
    "h_list = np.array([1])#, 0.05]) ## holding cost -- overage\n",
    "C = 9999 ## capacity constraint\n",
    "L = len(h_list)\n",
    "\n",
    "honesty = False; \n",
    "verbose = False; oracle = True;\n",
    "bootstrap = True; \n",
    "\n",
    "cond_mean = [lambda x: 3]#, lambda x: 3]\n",
    "cond_std = [lambda x: np.exp(x[:, 0])]#, lambda x: np.exp(x[:, 1])]\n",
    "\n",
    "risk_all = {}\n",
    "feature_split_all = {}\n",
    "results_eval_all = {}\n",
    "\n",
    "direct = ''\n",
    "date = ''\n",
    "output = \"nv_n.txt\"\n",
    "\n",
    "with open(output, 'w') as f:\n",
    "    print(\"Parameters set\", file = f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run opti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.6min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.6min finished\n"
     ]
    }
   ],
   "source": [
    "with open(output, 'w') as f:\n",
    "    print(\"start\", file = f)\n",
    "\n",
    "for N in N_list:\n",
    "    risk_all[str(N)] = {}\n",
    "    feature_split_all[str(N)] = {}\n",
    "    results_eval_all[str(N)] = {}\n",
    "\n",
    "    for p in p_list:\n",
    "        with open(output, 'a') as f:\n",
    "            print(\"N: \", N, file = f)\n",
    "            print(\"p: \", p, file = f)\n",
    "\n",
    "        n_proposals = N; \n",
    "        mtry = p;\n",
    "        subsample_ratio = 1;\n",
    "        max_depth=100; \n",
    "        min_leaf_size=10; \n",
    "        balancedness_tol = 0.2; \n",
    "\n",
    "#         X_list = [np.random.normal(size = (N, p)) for run in range(runs)]\n",
    "#         Y_list = [generate_Y(X_list[run], cond_mean, cond_std) for run in range(runs)]\n",
    "    \n",
    "        time1 = time.time()\n",
    "        results_fit = Parallel(n_jobs=n_jobs, verbose = 3)(delayed(compare_forest_one_run)(X_list[run], Y_list[run], X_list[run], Y_list[run], \n",
    "            h_list = h_list, b_list = b_list, C = C, \n",
    "            n_trees = n_trees, honesty= honesty, mtry = mtry, subsample_ratio = subsample_ratio, oracle = oracle, min_leaf_size = min_leaf_size, verbose = verbose, max_depth = max_depth, n_proposals = n_proposals, balancedness_tol = balancedness_tol, bootstrap = bootstrap) for run in range(runs))\n",
    "        time2 = time.time()\n",
    "        with open(output, 'a') as f:\n",
    "            print(\"time: \", time2 - time1, file = f)\n",
    "            print(\"------------------------\", file = f)\n",
    "\n",
    "#         time1 = time.time()\n",
    "#         results_eval = Parallel(n_jobs=n_jobs, verbose = 3)(delayed(evaluate_one_run)(results_fit[run], X_list[run], Y_list[run], X_list[run], Y_list[run], \n",
    "#             Nx_test, Ny_train, Ny_test, cond_mean, cond_std,  \n",
    "#             h_list =h_list, b_list = b_list, C = C, verbose = verbose) for run in range(runs))\n",
    "#         time2 = time.time()\n",
    "#         results_eval_all[str(N)][str(p)] = results_eval\n",
    "#         with open(output, 'a') as f:\n",
    "#             print(\"time: \", time2 - time1, file = f)\n",
    "#             print(\"------------------------\", file = f)\n",
    "\n",
    "#         risks = extract_risk(results_eval)\n",
    "#         with open(output, 'a') as f:\n",
    "#             print(\"risk with C\", C, file=f)\n",
    "#             for k,v in sorted(risks.items(), key = lambda x: x[1].mean()):\n",
    "#                 print(k,\"avg risk:\",np.mean(v),\"+-\", 2*np.std(v)/np.sqrt(len(v)), file=f)\n",
    "#             print(\"------------------------\", file = f)\n",
    "#         risk_all[str(N)][str(p)] = risks\n",
    "\n",
    "#         feature_split_freq = evaluate_feature_split_freq(results_fit, p)\n",
    "#         with open(output, 'a') as f:\n",
    "#             for k,v in sorted(feature_split_freq.items(), key = lambda x: x[1].mean(0)[0], reverse = True):\n",
    "#                 print(k,\"frac feat. slt.:\",v.mean(0), file = f)\n",
    "#             print(\"---\", file = f)\n",
    "#             print(\"----------------------\", file = f)\n",
    "#             print(\"----------------------\", file = f)\n",
    "#         feature_split_all[str(N)][str(p)] = feature_split_freq\n",
    "\n",
    "#         pickle.dump(risk_all, open(direct + date +  \"risk_n.pkl\", \"wb\"))\n",
    "#         pickle.dump(feature_split_all, open(direct + date +  \"feature_split_n.pkl\", \"wb\"))\n",
    "#         pickle.dump(results_eval_all, open(direct + date +  \"results_eval_n.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'rf_approx_sol': <tree.forest at 0x7f243a9cde50>,\n",
       "  'rf_approx_risk': <tree.forest at 0x7f243acc3790>,\n",
       "  'rf_rf': <tree.forest at 0x7f243a9a55d0>,\n",
       "  'rf_grf': <tree.forest at 0x7f243a9a5750>,\n",
       "  'rf_oracle': <tree.forest at 0x7f243a96f7d0>}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/firstusr/felix/Working/StochOptForestFork/newsvendor/nv_tree_utilities.py:44: RuntimeWarning: invalid value encountered in true_divide\n",
      "  w = w/w.sum()\n"
     ]
    }
   ],
   "source": [
    "(decisions,risk) = evaluate_one_run_original(results_fit[0],X_test, Y_test, Y_train, h_list =h_list, b_list = b_list, C = C, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,r in risk.items():\n",
    "    print('{}: {}'.format(k,r.mean()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
